\chapter{Optimisation with Flambda}
\pdfchapterfold{-9}{Optimisation with Flambda}
%HEVEA\cutname{flambda.html}

\section{Overview}

{\em Flambda} is the term used to describe a series of new optimisation
passes introduced with OCaml 4.03.  These passes form a new
``middle-end'' of the native code compiler: they come after parsing and type
inference, but before the lower-level backend passes that ultimately lead
to machine code.

Flambda aims to make it easier to write idiomatic OCaml code without
incurring performance penalties.

To use the Flambda optimisers it is necessary to pass the {\tt -flambda}
option to the OCaml {\tt configure} script.  Code compiled with Flambda
cannot be linked into the same program as code compiled without Flambda.
Attempting to do this will result in a compiler error.

Consult the {\em Glossary} at the end of this chapter for definitions of
technical terms used below.

\section{Command-line flags}

The Flambda optimisers provide a variety of command-line flags that may
be used to control their behaviour.  Detailed descriptions of each flag
are given in the sections that follow.

Commonly-used options:
\begin{options}
\item[\machine{-O2}] Perform more optimisation than usual.  Compilation
times may be lengthened.
\item[\machine{-O3}] Perform even more optimisation than usual, possibly
including unrolling of recursive functions.  Compilation times may be
significantly lengthened.
\item[\machine{-Oclassic}] Make inlining decisions at the point of
definition of a function rather than at the call site(s).  This mirrors
the behaviour of OCaml compilers not using Flambda.  It produces
smaller {\tt .cmx} files, shorter compilation times and code that probably
runs rather slower.
\item[\machine{-inlining-report}] Emit {\tt .inlining} files (one per
round of optimisation) showing all of the inliner's decisions.
\end{options}

Less commonly-used options:
\begin{options}
\item[\machine{-remove-unused-arguments}] Remove unused function arguments
even when the argument is not specialised.
\item[\machine{-unbox-closures}] Pass free variables via specialised arguments
rather than closures.
\end{options}

Advanced options:
\begin{options}
\item[\machine{-inline}] Controls the aggressiveness of the search for
inlining opportunities.
\item[\machine{-inline-branch-factor},
  \machine{-inline-alloc-cost},
  \machine{-inline-branch-cost},
  \machine{-inline-call-cost},
  \machine{-inline-indirect-cost},
  \machine{-inline-prim-cost}] Controls how the inliner assesses the runtime
performance penalties associated with various operations.
\item[\machine{-inline-lifting-benefit},
  \machine{-inline-toplevel}] Controls inlining at toplevel.
\item[\machine{-inline-max-depth}] A hard limit on the depth of the
search for inlining opportunities.
\item[\machine{-inline-max-unroll}] The maximum number of times a given
function may be unrolled per round of optimisation.
\item[\machine{-no-unbox-free-vars-of-closures}] %
Do not unbox closure variables.
\item[\machine{-no-unbox-specialised-args}] %
Do not unbox arguments to which functions have been specialised.
\item[\machine{-rounds}] How many rounds of optimisation to perform.
\item[\machine{-unbox-closures-factor}] Scaling factor for benefit
calculation when using {\tt -unbox-closures}.
\end{options}

\paragraph{Notes}
\begin{itemize}
\item Flambda-specific flags are silently accepted even when the
{\tt -flambda} option was not provided to the {\tt configure} script.
This is intended to make it more
straightforward to run benchmarks with and without the Flambda optimisers
in effect.
\item Some of the Flambda flags may be subject to change in future
releases.
\end{itemize}

\subsection{Specification of optimisation parameters by round}

Flambda operates in {\em rounds}: one round consists of a certain sequence
of transformations that may then be repeated in order to achieve more
satisfactory results.  The number of rounds can be set manually using the
{\tt -rounds} parameter (although this is not necessary when using
predefined optimisation levels such as with {\tt -O2} and {\tt -O3};
see below).
For high optimisation the number of rounds might be set at 3 or 4.

Command-line flags that may apply per round, for example those with
{\tt "-cost"} in the name, accept arguments of the form:
\begin{center}
{\em n}{\tt\ |\ }{\em round}{\tt =}{\em n}[{\tt,}...]
\end{center}
In other words, one may specify the value(s) to use for some or all rounds.
If no {\em round} is given then the value will apply to all rounds.

The flags {\tt -Oclassic}, {\tt -O2} and {\tt -O3} are applied before all
other flags, meaning that certain parameters may be overridden without
having to specify every parameter usually invoked by the given optimisation
level.

\section{Inlining}

Flambda provides significantly enhanced inlining capabilities relative to
previous versions of the compiler.  Unlike such previous versions, all
functions are eligible for inlining.

\subsection{When inlining is performed}

Inlining is performed together with all of the other Flambda optimisation
passes, that is to say, after closure conversion.  This has three particular
advantages over a potentially more straightforward implementation prior to
closure conversion:
\begin{itemize}
\item It permits higher-order inlining, for example when a non-inlinable
function always returns the same function yet with different environments
of definition.  Not all such cases are supported yet, but it is intended
that such support will be improved in future.
\item It is easier to integrate with cross-module optimisation, since
imported information about other modules is already in the correct
intermediate language.
\item It becomes more straightforward to control which variables end up
in which closures, helping to avoid closure bloat.
\end{itemize}

\subsection{Classic inlining heuristic}

In {\tt -Oclassic} mode the behaviour of Flambda mimics previous versions
of the compiler.  At the definition site of a function, the body of the
function is measured.  It will then be marked as eligible for inlining
(and hence inlined at every direct call site) if:
\begin{itemize}
\item the measured size (in unspecified units) is smaller than that of a
function call plus the argument of the {\tt -inline} command-line flag; and
\item the function does not contain a definition of (another) function; and
\item the function is not recursive.
\end{itemize}

This contrasts to the normal Flambda mode, that is to say
without {\tt -Oclassic}, where:
\begin{itemize}
\item the inlining decision is made at the {\bf call site};
\item local functions do not prevent their parents from being inlined;
\item recursive functions can be handled, by {\em specialisation} (see
below);
\item functions that are only discovered after an initial pass of inlining
may themselves be eligible for inlining.
\end{itemize}

Making the inlining decision at the call site helps in situations where
the context is important.  For example:
\begin{verbatim}
let f b x =
  if b then
    x
  else
    ... big expression ...

let g x = f true x
\end{verbatim}
In this case, we would like to inline {\tt f} into {\tt g}, because a
conditional jump can be eliminated and the code size should reduce.  If the
inlining decision has been made after the declaration of {\tt f} without
seeing the use, its size would have probably made it ineligible for
inlining; but at the call site, its final size can be known.  Further,
this function should probably not be inlined systematically: if {\tt b}
is unknown, or indeed {\tt false}, there is little benefit to trade off
against a large increase in code size.  In the existing non-Flambda inliner
this isn't a great problem because chains of inlining were cut off farly
quickly.  However it has led to excessive use of overly-large inlining
parameters such as {\tt -inline 10000}.

The remainder of this section discusses the various strategies available
in the normal Flambda mode.

\subsection{Assessment of inlining benefit}

The various inlining strategies described below involve a {\em search}
that performs exploratory applications of an inlining strategy at call
sites.  (The search procedure is described fully in the next subsection.)
After having performed each exploratory inlining a decision is made as to
whether to keep the resulting inlined version of the code.


Inlining typically
results in an increase in code size, which if left unchecked, may not only
lead to grossly large executables and excessive compilation times but also
a decrease in performance due to worse locality.  As such, the
Flambda inliner trades off the change in code size against
the expected runtime performance benefit, with the benefit being computed
based on the number of operations that the compiler observes may be removed
as a result of inlining.  For example in the previous example:
\begin{verbatim}
let f b x =
  if b then
    x
  else
    ... big expression ...

let g x = f true x
\end{verbatim}
it would be observed that inlining of {\tt f} would remove:
\begin{itemize}
\item one direct call;
\item one conditional branch.
\end{itemize}

Formally, an estimate of runtime performance benefit is computed by summing
the cost of the operations that are known to be removed as a result of the
inlining and subsequent simplification of the inlined body.
The individual costs for the various kinds of operations may be adjusted
using the various {\tt -inline-...-cost} flags:
\begin{options}
\item[\machine{-inline-alloc-cost}] The cost of an allocation.
\item[\machine{-inline-branch-cost}] The cost of a branch.
\item[\machine{-inline-call-cost}] The cost of a direct function call.
\item[\machine{-inline-indirect-cost}] The cost of an indirect function call.
\item[\machine{-inline-prim-cost}] The cost of a {\em primitive}.  Primitives
encompass operations including arithmetic and memory access.
\end{options}

The change in code size is also estimated: morally speaking it should be the
change in machine code size, but since that is not available to the inliner,
an approximation is used.

new strategy for this section:
- determine the benefit without inlining inside the function
- if good enough, inline it
- if not, speculatively inline inside the function, then re-evaluate,
including the benefit gained from any internal inlinings.  (inlining thresh
and depth discussion only for this part).
...and say, if the function is recursive, then the unrolling depth is
incremented too.  (This depth basically affects whether a call site is considered
or not.)

If the benefit exceeds the increase in code size then the inlined version of
the function will be kept.

\subsection{Inlining search procedure}

The inliner traverses the program looking for direct call sites.  At each
such call site inlining will be attempted unless the search
is cut off by one of three things:
\begin{itemize}
\item the {\em inlining threshold} (as set initially by {\tt -inline}
or {\tt -inline-toplevel}) having been exhausted; or
\item the {\em inlining depth} has reached the maximum (as set by
{\tt -inline-max-depth); or
\item the call is to a recursive function and the unrolling depth for
that function has reached the maximum (as set by
{\tt -inline-max-unroll}).
\item the direct call in question is a call to the function containing
that call.
\end{itemize}

When attempting to inline a function, the search procedure recurses into the
body of that function; the inliner does not yet know whether the function
will actually be inlined.  As such, the inlining decisions taken on the
body may be seen as {\em speculative}; further, they are constrained by
the inlining threshold and inlining depth to keep the search procedure
operating in a reasonable time.  The inlining threshold is reduced, when
speculating, by the size of an inlined function; the depth is increased
by one every time the inliner recurses into another function.






It should be noted that in certain circumstances, to keep compilation times
under control, the search may be automatically cut off based on information
known to the inliner.  For example, certain larger non-recursive functions
may never be considered for inlining if it is known that the contextual
information available to the inliner would be insufficient for the inlining
to be beneficial.

\subsection{Inlining of functions}

Inlining of a function proceeds by taking a copy of the body and inserting
it at the call site, with the parameters bound appropriately.  (This happens
for both non-recursive and recursive functions; however, for recursive
functions the behaviour is restricted by the unrolling depth.)

\subsection{Inlining of functors}

There is nothing particular about functors that inhibits inlining compared
to normal functions.  To the inliner, these both look the same, except
that functors are marked as such.

Applications of functors at toplevel will be given
an additional benefit (which may be controlled by the
{\tt -inline-lifting-benefit} flag) to bias inlining in such situations
towards keeping the inlined version.

Applications of functors not at toplevel, for example in a local module
inside some other expression, are treated by the inliner identically to
normal function calls.

% Make this a \section?
\subsection{Specialisation of recursive functions}

The inliner may discover a call site to a recursive function where
something is known about the arguments: for example, they may be equal to
some other variables currently in scope.  In this situation it may be
beneficial to {\em specialise} the function to those arguments.  This is
done by copying the declaration of the function (and any others involved
in any same mutually-recursive declaration) and noting the extra information
about the arguments.  The arguments augmented by this information are known
as {\em specialised arguments}.  In order to try to ensure that specialisation
is not performed uselessly, arguments are only specialised if it can be shown
that they are {\em invariant}: in other words, during the execution of the
recursive function(s) themselves, the arguments never change.

\paragraph{Example: the well-known {\tt List.iter} function}
This function might be written like so:
\begin{verbatim}
let rec iter f l =
  match l with
  | [] -> ()
  | h :: t ->
    f h;
    iter f t
\end{verbatim}
and used like this:
\begin{verbatim}
let do_iter f =
  iter f [1; 2; 3]
\end{verbatim}
...
(an example here f and g swap between two functions)
...
\paragraph{Aside on invariant parameters.} ...
\begin{verbatim}
let rec iter_swap f g l =
  match l with
  | [] -> ()
  | 0 :: t ->
    iter_swap g f l
  | h :: t ->
    f h;
    iter_swap f g t
\end{verbatim}

Unless overridden by an attribute (see below), specialisation of a function
will not be attempted if:
\begin{itemize}
\item the compiler is in {\tt -Oclassic} mode;
\item the function is not obviously recursive;
\item the function is not closed.
\end{itemize}

It should be noted that the {\em unboxing of closures} pass (see below)
can introduce specialised arguments on non-recursive functions.  (No other
place in the compiler currently does this.)

\subsection{Unrolling of recursive functions}

If {\tt -O3} optimisation level is selected and/or the {\tt -inline-max-unroll}
flag is passed with an argument greater than zero, the compiler will
consider recursive functions as eligible for unrolling (analogous to
loop peeling).

Unrolling of a recursive function consists of applying the transformation for
inlining non-recursive functions at the recursive call site(s) of the
function.

\subsection{Inlining reports}

If the {\tt -inlining-report} option is provided to the compiler then a file
will be emitted corresponding to each round of optimisation.  The files
are named {\tt basename.}{\em round}{\tt.inlining.org} with {\em round} a
zero-based integer.  Inside the files, which are formatted as ``org mode'',
will be found English prose describing the decisions that the inliner took.

\subsection{Directing the inliner}

Should the inliner prove recalcitrant and refuse to inline a particular
function, or if the observed inlining decisions are not to the programmer's
satisfaction for some other reason, inlining behaviour can be dictated by the
programmer directly in the source code.
One example where this might be appropriate is when the programmer,
but not the compiler, knows that a particular function call is on a cold
code path.  It might be desirable to prevent inlining of the function so
that the code size along the hot path is kept smaller, such as to increase
locality.

The inliner is directed using attributes.
For non-recursive functions (and one-step unrolling of recursive functions,
although {\tt [\@unroll]} is more clear for this purpose)
the following are supported:
\begin{options}
\item[{\machine{\@\@inline always}} or {\machine{\@\@inline never}}] Attached
to a declaration of a function or functor, these direct the inliner to either
always or never inline, irrespective of the size/benefit calculation.  (If
the function is recursive then the body is substituted and no special
action is taken for the recursive call site(s).)
\item[{\machine{\@inlined always}} or {\machine{\@inlined never}}] Attached
to a function application, these direct the inliner likewise.  These
attributes at call sites override any other attribute that may be present
on the corresponding declaration.
\end{options}

For recursive functions the relevant attributes are:
\begin{options}
\item[{\machine{\@\@specialise}}] Attached to a declaration of a function
or functor, this directs the inliner to always specialise the function so
long as it has appropriate contextual knowledge, irrespective of the
size/benefit calculation.
\item[{\machine{\@specialised}}] Attached to a function application, this
directs the inliner likewise.  This attribute at a call site overrides any
other attribute that may be present on the corresponding declaration.
(Note that the function will still only be specialised if there exist
one or more invariant parameters whose values are known.)
\item[{\machine{\@unrolled }}$n$] This attribute is attached to a function
application and takes an integer argument.  Each time the inliner sees
the attribute it behaves as follows:
\begin{itemize}
\item If $n$ is zero or less, nothing happens.
\item Otherwise the function being called is substituted at the call site
with its body having been rewritten such that 
any recursive calls to that function {\em or
any others in the same mutually-recursive group} are annotated with the
attribute {\tt unrolled(}$n - 1${\tt )}.  Inlining may continue on that body.
\end{itemize}
As such, $n$ behaves as the ``maximum depth of unrolling''.
\end{options}

A compiler warning will be emitted if it was found impossible to obey an
annotation from an {\tt [\@inlined]} or {\tt [\@specialised]}
attribute.

\paragraph{Example showing correct placement of attributes}
\begin{verbatim}
module F (M : sig type t end) = struct
  let bar x =
    x * 3
  [@@inline never]

  let foo x =
    (bar [@inlined]) (42 + x)
end [@@inline never]

module X = F [@inlined] (struct type t = int end)
\end{verbatim}

\section{Code transformations}

This section details the general code transformations performed by
the Flambda passes.  Transformations are permanently enabled unless noted
otherwise.

\subsection{Simplification}

The {\em simplification} transformation propagates information (known as
{\em approximations}) about which
variables hold what values at runtime.  Certain relationships between
variables and symbols are also tracked: for example, some variable may be
known to always hold the same value as some other variable; or perhaps
some variable may be known to always hold the value pointed to by some
symbol.

The propagated information
effectively forms a kind of type system on Flambda terms.

The propagation can help to eliminate allocations in cases such as:
\begin{verbatim}
let f x y =
  ...
  let p = x, y in
  ...
  ... (fst p) ... (snd p) ...
\end{verbatim}
The projections from {\tt p} may be replaced by uses of the variables
{\tt x} and {\tt y}, potentially meaning that {\tt p} becomes unused.

The propagation performed by the simplification pass is also important for
discovering which functions flow to indirect call sites.  This can enable
the transformation of such call sites into direct call sites, which makes
them eligible for an inlining transformation.

\subsection{Lifting of constants}

Expressions found to be constant will be lifted to symbol bindings when
they evaluate to boxed values.  Such constants may be straightforward numeric
constants, such as the floating-point number {\tt 42.0}, or more complicated
values such as constant closures.

Lifting of constants to toplevel reduces allocation at runtime.

The compiler aims to share constants lifted to toplevel such that there
are no duplicate definitions.  However if {\tt .cmx} files are hidden
from the compiler then maximal sharing may not be possible.

\paragraph{Notes about float arrays} %
The following rules apply specifically to constant float arrays:
\begin{itemize}
\item Float arrays at the toplevel are mutable and never shared.  (That
is to say, for each
such definition there is a distinct symbol in the data section of the object
file pointing at the array.)
\item Float arrays not at toplevel are mutable and are created each time the
expression is evaluated.  This can be thought of as an operation that takes
an immutable array (which in the source code has no associated name; let
us call it the {\em initialising array}) and
duplicates it into a fresh mutable array.
\begin{itemize}
\item If the array is of size four or less, the expression will create a
fresh block and write the values into it one by one.  There is no reference
to the initialising array as a whole.

\item Otherwise, the initialising array is lifted out and subject to the
normal constant sharing procedure;
creation of the array consists of bulk copying the initialising array
into a fresh value on the OCaml heap.
\end{itemize}
\end{itemize}

\subsection{Lifting of toplevel let bindings}

Toplevel {\tt let}-expressions may be lifted to symbol bindings to ensure
that the corresponding bound variables are not captured by closures.  If the
defining expression of a given binding is found to be constant, it is bound
as such (the technical term is a {\em let-symbol} binding).

Otherwise, the symbol is bound to a (statically-allocated)
{\em preallocated block} containing one field.  At runtime, the defining
expression will be evaluated and the first field of the block filled with
the resulting value.  This {\em initialise-symbol} binding
causes one extra indirection but ensures, by
virtue of the symbol's address being known at compile time, that uses of the
value are not captured by closures.

It should be noted that the blocks corresponding to initialise-symbol
bindings are kept alive forever, by virtue of them occurring in a static
table of GC roots within the object file.  This extended lifetime of
expressions may on occasion be surprising.

\subsection{Transformation of non-escaping references into mutable variables}

Flambda performs a simple analysis analogous to that performed elsewhere
in the compiler that can transform {\tt ref}s into mutable variables
that may then be held in registers (or on the stack as appropriate) rather
than being allocated on the OCaml heap.  This only happens so long as the
reference concerned can be shown to not escape from its defining scope.

\subsection{Substitution of closure variables for specialised arguments}

This transformation discovers closure variables that are known to be
equal to specialised arguments.  Such closure variables are replaced by
the specialised arguments; the closure variables may then be removed by
the ``removal of unused closure variables'' pass (see below).

\section{Unboxing transformations}

The transformations in this section relate to the splitting apart of
{\em boxed} (that is to say, non-immediate) values.  They are largely
intended to reduce allocation, which tends to result in a runtime
performance profile with lower variance and smaller tails.

\subsection{Unboxing of closure variables}

This transformation is enabled by default.  It may be disabled using the
{\tt -no-unbox-free-vars-of-closures} flag.

Variables that appear in closure environments may themselves be boxed
values.  As such, they may be split into further closure variables, each
of which corresponds to some projection from the original closure variable(s).
This transformation is called {\em unboxing of closure variables} or
{\em unboxing of free variables of closures}.  It is only applied when
reasonable certainty that there are no uses of the boxed free variable itself
within the corresponding function bodies.
% CR mshinwell: Actually, we probably don't check this carefully enough.
% It needs a global analysis in case there is an out-of-scope projection.

\paragraph{Example:} In the following code, the compiler observes that
the closure returned from the function {\tt f} has a free variable {\tt pair}
that may be split into two separate variables.
\begin{verbatim}
let f x0 x1 =
  let pair = x0, x1 in
  Printf.printf "foo\n";
  fun y ->
    fst pair + snd pair + y
\end{verbatim}
After some simplification one obtains:
\begin{verbatim}
let f x0 x1 =
  let pair_0 = x0 in
  let pair_1 = x1 in
  Printf.printf "foo\n";
  fun y ->
    pair_0 + pair_1 + y
\end{verbatim}
and then:
\begin{verbatim}
let f x0 x1 =
  Printf.printf "foo\n";
  fun y ->
    x0 + x1 + y
\end{verbatim}
The allocation of the pair has been eliminated.

This transformation does not operate if it would cause the closure to
contain more than twice as many closure variables as it did beforehand.

\subsection{Unboxing of specialised arguments}

This transformation is enabled by default.  It may be disabled using the
{\tt -no-unbox-specialised-args} flag.

It may become the case during compilation that one or more invariant arguments
to a function become specialised to a particular value.  When such values are
themselves boxed the corresponding specialised arguments may be split into
more specialised arguments corresponding to the projections out of the boxed
value that occur within the function body.  This transformation is called
{\em unboxing of specialised arguments}.  It is only applied when there is
reasonable certainty that the boxed argument itself is unused within the
function.

If the function in question is involved in a recursive group then unboxing
of specialised arguments may be immediately replicated across the group
based on the dataflow between invariant arguments.

\paragraph{Example:} In the following code, having inlined {\tt loop}
into {\tt f}, the compiler observes {\tt env}
being invariant and always the pair formed by adding {\tt 42} and {\tt 43}
to the argument {\tt x} of the function {\tt f}.
\begin{verbatim}
let rec loop inv xs =
  match xs with
  | [] -> fst inv + snd inv
  | x::xs -> x + loop2 xs inv
and loop2 ys inv =
  match ys with
  | [] -> 4
  | y::ys -> y - loop inv ys

let f x =
  Printf.printf "%d\n" (loop (x + 42, x + 43) [1;2;3])
\end{verbatim}
Since the functions have sufficiently few arguments, more specialised
arguments will be added.  After some simplification one obtains:
\begin{verbatim}
let f x =
  let rec loop' xs inv_0 inv_1 =
    match xs with
    | [] -> inv_0 + inv_1
    | x::xs -> x + loop2' xs inv_0 inv_1
  and loop2' ys inv_0 inv_1 =
    match ys with
    | [] -> 4
    | y::ys -> y - loop' ys inv_0 inv_1
  in
  Printf.printf "%d\n" (loop' (x + 42) (x + 43) [1;2;3])
\end{verbatim}
The allocation of the pair within {\tt f} has been removed.  Since the
two closures for {\tt loop'} and {\tt loop2'} are constant they will be
lifted to toplevel with no runtime allocation penalty.

The transformation to unbox specialised arguments never introduces extra
allocation.

The transformation will not unbox arguments if it would result in the
original function having sufficiently many arguments so as to inhibit
tail-call optimisation.

The transformation is implemented by creating a wrapper function that
accepts the original arguments.  Meanwhile, the original function is renamed
and extra arguments are added corresponding to the unboxed specialised
arguments; this new function
is called from the wrapper.  The wrapper will then be inlined
at direct call sites.  Indeed, all call sites will be direct unless
{\tt -unbox-closures} is being used, since they will have been generated
by the compiler when originally specialising the function.  (In the case
of {\tt -unbox-closures} other functions may appear with specialised
arguments; in this case there may be indirect calls and these will incur
a small penalty owing to having to bounce through the wrapper.  The technique
of {\em direct call surrogates} used for {\tt -unbox-closures} is not
used by the transformation to unbox specialised arguments.)

\subsection{Unboxing of closures}

This transformation is {\em not} enabled by default.  It may be enabled
using the {\tt -unbox-closures} flag.

The transformation replaces closure variables by specialised arguments.
The aim is to cause more closures to become closed.  It is particularly
applicable, as a means of reducing allocation, where the function concerned
cannot be inlined or specialised.  For example, some non-recursive function
might be too large to inline; or some recursive function might offer
no opportunities for specialisation perhaps because its only argument is
one of type {\tt unit}.

\paragraph{Simple example:} In the following code (which might typically
occur when {\tt g} is too large to inline) the value of {\tt x} would usually
be communicated to the application of the {\tt +} function via the closure
of {\tt g}.
\begin{verbatim}
let f x =
  let g y =
    x + y
  in
  (g [@inlined never]) 42
\end{verbatim}
Unboxing of the closure causes the value for {\tt x} inside {\tt g} to
be passed as an argument to {\tt g} rather than through its closure.  This
means that the closure of {\tt g} becomes constant and may be lifted to
toplevel, eliminating the runtime allocation.

The transformation is implemented by adding a new wrapper function in the
manner of that used when unboxing specialised arguments.  The closure
variables are still free in the wrapper, but the intention is that when
the wrapper is inlined at direct call sites, the relevant values are
passed directly to the main function via the new specialised arguments.

Adding such a wrapper will penalise indirect calls to the function
(which might exist in arbitrary places; remember that this transformation
is not for example applied only on functions the compiler has produced
as a result of specialisation) since such calls will bounce through
the wrapper.  To
mitigate this, if a function is small enough when weighed up against
the number of free variables being removed, it will be duplicated by the
transformation to obtain two versions: the original (used for indirect calls,
since we can do no better) and the wrapper/rewritten function pair as
described in the previous paragraph.  The wrapper/rewritten function pair
will only be used at direct call sites of the function.  (The wrapper in
this case is known as a {\em direct call surrogate}, since
it takes the place of another function---the unchanged version used for
indirect calls---at direct call sites.)

The {\tt -unbox-closures-factor} command line flag, which takes an
integer, may be used to adjust the point at which a function is deemed
large enough to be ineligible for duplication.  The benefit of
duplication is scaled by the integer before being evaluated against the
size.

\paragraph{Harder example:} In the following code, there are two closure
variables that would typically cause closure allocations.  One is called
{\tt fv} and occurs inside the function {\tt baz}; the other is called
{\tt z} and occurs inside the function {\tt bar}.
In this toy (yet sophisticated) example we again use an attribute to
simulate the typical situation where the first argument of {\tt baz} is
too large to inline.
\begin{verbatim}
let foo c =
  let rec bar zs fv =
    match zs with
    | [] -> []
    | z::zs ->
      let rec baz f = function
        | [] -> []
        | a::l -> let r = fv + ((f [@inlined never]) a) in r :: baz f l
      in
      (map2 (fun y -> z + y) [z; 2; 3; 4]) @ bar zs fv
  in
  Printf.printf "%d" (List.length (bar [1;2;3;4] c))
\end{verbatim}
The resulting code passes the free variables via function arguments in
order to eliminate all closure allocation in this example (aside from any
that may be performed inside {\tt printf}).

\section{Transformations that remove unused code and values}

\subsection{Removal of redundant let expressions}

The simplification pass removes unused {\tt let} bindings so long as
their corresponding defining expressions have ``no effects''.  See
the section ``Treatment of effects'' below for the precise definition of
this term.

\subsection{Removal of redundant program constructs}

This transformation is analogous to the removal of {\tt let}-expressions
whose defining expressions have no effects.  It operates instead on symbol
bindings, removing those that have no effects.

\subsection{Removal of unused arguments}

This transformation is only enabled by default for specialised arguments.
It may be enabled for all arguments using the {\tt -remove-unused-arguments}
flag.

The pass analyses functions to determine which arguments are unused.
Removal is effected by creating a wrapper function, which will be inlined
at every direct call site, that accepts the original arguments and then
discards the unused ones before calling the original function.  As a
consequence, this transformation may be detrimental if the original
function is usually indirectly called, since such calls will now bounce
through the wrapper.  (The technique of {\em direct call surrogates} used
to reduce this penalty during unboxing of closure variables (see above)
does not yet apply to the pass that removes unused arguments.)

\subsection{Removal of unused closure variables}

This transformation performs an analysis across
the whole compilation unit to determine whether there exist closure variables
that are never used.  Such closure variables are then eliminated.  (Note that
this has to be a whole-unit analysis because a projection of a closure
variable from some particular closure may have propagated to an arbitrary
location within the code due to inlining.)

\section{Treatment of effects}

The Flambda optimisers classify expressions in order to determine whether
an expression:
\begin{itemize}
\item does not need to be evaluated at all; and/or
\item may be duplicated.
\end{itemize}

This is done by forming judgements on the {\em effects} and the {\em coeffects}
that might be performed were the expression to be executed.  Effects talk
about how the expression might affect the world; coeffects talk about how
the world might affect the expression.

Effects are classified as follows:
\begin{itemize}
\item[{\bf No effects:}] The expression does not change the observable state
of the world.  For example, it must not write to any mutable storage,
call arbitrary external functions or change control flow (e.g. by raising
an exception).  Note that allocation is {\em not} classed as having
``no effects'' (see below).
\begin{itemize}
\item It is assumed in the compiler that expressions with no
effects, whose results are not used, may be eliminated.  (This typically
happens where the expression in question is the defining expression of a
{\tt let}; in such cases the {\tt let}-expression will be
eliminated.) It is further
assumed that such expressions with no effects may be
duplicated (and thus possibly executed more than once).
\item (Exceptions arising from allocation points, for example
``out of memory'' or
exceptions propagated from finalizers or signal handlers, are treated as
``effects out of the ether'' and thus ignored for our determination here
of effectfulness.  The same goes for floating point operations that may
cause hardware traps on some platforms.)
\end{itemize}
\item[{\bf Only generative effects:}] The expression does not change the
observable state of the world save for possibly affecting the state of
the garbage collector by performing an allocation.  Expressions
that only have generative effects and whose results are unused
may be eliminated by the compiler.  However, unlike expressions with
``no effects'', such expressions will never be eligible for duplication.
\item[{\bf Arbitrary effects:}] All other expressions.
\end{itemize}

There is a single classification for coeffects:
\begin{itemize}
\item[{\bf No coeffects:}] The expression does not observe the effects (in
the sense described above) of other expressions.  For example, it must not
read from any mutable storage or call arbitrary external functions.
\end{itemize}

It is assumed in the compiler that, subject to data dependencies,
expressions with neither effects nor coeffects may be reordered with
respect to other expressions.

\section{Compilation of statically-allocated modules}

Compilation of modules that are able to be statically allocated (for example,
the module corresponding to an entire compilation unit, as opposed to a first
class module dependent on values computed at runtime) initially follows the
strategy used for bytecode.  A sequence of {\tt let}-bindings, which may be
interspersed with arbitrary effects, surrounds a record creation that becomes
the module block.  The Flambda-specific transformation follows: these bindings
are lifted to toplevel symbols, as described above.

\section{Glossary}

The following terminology is used in this chapter of the manual.

\begin{itemize}
\item[{\bf Closed function}] A function whose body has no free variables
except its parameters and any to which are bound other functions within
the same (possibly mutually-recursive) declaration.
\item[{\bf Closure}] The runtime representation of a function.  This
includes pointers to the code of the function
together with the values of any variables
that the function references from its environment of definition.
The values of such variables are required because the function may be
invoked from a place where the original bindings of such variables are
no longer in scope.  The set of such variables in a given closure is
sometimes known as the {\em environment}.  A group of possibly
mutually-recursive functions defined using {\em let rec} all share a
single closure.  (Note to developers: in the Flambda source code a
{\em closure} always corresponds to a single function; a
{\em set of closures} refers to a group of such.)
\item[{\bf Closure variable}]  A member of the environment held within the
closure of a given function.
\item[{\bf Constant}]  Some entity (typically an expression) the value of which
is known by the compiler at compile time.  Constantness may be explicit from
the source code or inferred by the Flambda optimisers.
\item[{\bf Constant closure}] A closure that is statically allocated in an
object file.  It is almost always the case that the environment portion of
such a closure is empty.
\item[{\bf Defining expression}]  The expression {\tt e} in %
{\tt let x = e in e'}.
\item[{\bf Direct call site}]  A place in a program's code where a function is
called and it is known at compile time which function it will always be.
\item[{\bf Indirect call site}]  A place in a program's code where a function
is called but is not known to be a {\em direct call site}.
\item[{\bf Program}]  A collection of {\em symbol bindings}.
\item[{\bf Specialised argument}]  An argument to a function that is known
to always hold a particular value at runtime.  These are introduced by the
inliner when specialising recursive functions; and the {\tt unbox-closures}
pass.
\item[{\bf Symbol}]  A name referencing a particular place in an object file
or executable image.  At that particular place will be some constant value.
Symbols may be examined using operating system-specific tools (for
example {\tt objdump} on Linux).
\item[{\bf Symbol binding}]  Analogous to a {\em let}-expression but working
at the level of symbols defined in the object file.  The address of a symbol is
fixed, but it may be bound to both constant and non-constant expressions.
\item[{\bf Toplevel}]  An expression in the current program which is not
enclosed within any function declaration.
\item[{\bf Variable}]  A named entity to which some OCaml value is bound by a
{\tt let} expression, pattern-matching construction, or similar.
\end{itemize}
